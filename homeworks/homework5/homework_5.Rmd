---
title: "Homework 4"
output:
  pdf_document: default
  html_notebook: default
editor_options: 
  chunk_output_type: inline
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```

*Ginevra Carbone*
  
# Chapter 6  
  
## Exercise 6

The following investigates the consequences of not using a logarithmic transformation for the `nihills` data analysis. The second differs from the first in having a `dist × climb` interaction term, additional to linear terms in `dist` and `climb`.

(a) Fit the two models:
```{r echo=TRUE}

nihills.lm <- lm(time ~ dist+climb, data=nihills)
nihills2.lm <- lm(time ~ dist+climb+dist:climb, data=nihills)
anova(nihills.lm, nihills2.lm)
```

(b) Using the F -test result, make a tentative choice of model, and proceed to examine diag-
nostic plots. Are there any problematic observations? What happens if these points are
removed? Refit both of the above models, and check the diagnostics again.

## Exercise 7

Check the variance inflation factors for `bodywt` and `lsize` for the model `brainwt ~ bodywt + lsize`, fitted to the `litters` data set. Comment.

```{r echo=TRUE}
```

## Exercise 8

Apply the `lm.ridge()` function to the litters data, using the generalized cross-validation (GCV) criterion to choose the tuning parameter. (GCV is an approximation to cross-validation.)

(a) In particular, estimate the coefficients of the model relating `brainwt` to `bodywt` and `lsize` and compare with the results obtained using `lm()`.

(b) Using both ridge and ordinary regression, estimate the mean brain weight when litter size is 10 and body weight is 7. Use the bootstrap, with case-resampling, to compute approximate 95% percentile confidence intervals using each method. Compare with the interval obtained using `predict.lm()`.

## Exercise 10

The data frame table.b3 in the MPV package contains data on gas mileage and 11 other variables for a sample of 32 automobiles.

(a) Construct a scatterplot of `y` (mpg) versus `x1` (displacement). Is the relationship between these variables non-linear?

(b) Use the `xyplot()` function, and `x11` (type of transmission) as a group variable. Is a linear model reasonable for these data?

(c) Fit the model relating `y` to `x1` and `x11` which gives two lines having possibly different slopes and intercepts. Check the diagnostics. Are there any influential observations? Are there any influential outliers?

(d) Plot the residuals against the variable `x7` (number of transmission speeds), again using `x11` as a group variable. Is there anything striking about this plot?

# Chapter 8

## Exercise 1

The following table shows numbers of occasions when inhibition (i.e., no flow of current across a membrane) occurred within 120 s, for different concentrations of the protein peptide-C (data
are used with the permission of Claudia Haarmann, who obtained these data in the course of her PhD research). The outcome yes implies that inhibition has occurred.
Use logistic regression to model the probability of inhibition as a function of protein concentration.

## Exercise 2

In the data set (an artificial one of 3121 patients, that is similar to a subset of the data ana-lyzed in Stiell et al., 2001) minor.head.injury, obtain a logistic regression model relating clinically.important.brain.injury to other variables. Patients whose risk is sufficiently high will be sent for CT (computed tomography). Using a risk threshold of 0.025 (2.5%), turn the result into a decision rule for use of CT.

## Exercise 5

Use the function `logisticsim()` (in the DAAG package) to simulate data from a logistic regression model to study the `glm()` function. For example, you might try experiments such as
the following:

(a) Simulate 100 observations from the model $$ logit(x) = 2 − 4x $$ for $x = 0, 0.01, 0.02, . . . , 1.0$. [This is the default setting for logisticsim().]

(b) Plot the responses ($y$) against the “dose” ($x$). Note how the pattern of 0s and 1s changes as $x$ increases.

(c) Fit the logistic regression model to the simulated data, using the binomial family. Compare the estimated coefficients with the true coefficients. Are the estimated coefficients
within about 2 standard errors of the truth?

(d) Compare the estimated logit function with the true logit function. How well do you think the fitted logistic model would predict future observations? For a concrete indication of the
difference, simulate a new set of 100 observations at the same x values, using a specified pseudorandom number generator seed and the true model. Then simulate some predicted observations using the estimated model and the same seed.

## Exercise 6

As in the previous exercise, the function `poissonsim()` allows for experimentation with Poisson regression. In particular, `poissonsim()` can be used to simulate Poisson responses with log-rates equal to $a + bx$, where $a$ and $b$ are fixed values by default.

(a) Simulate 100 Poisson responses using the model $$log λ = 2 − 4x$$ for $x = 0, 0.01, 0.02 . . . , 1.0$. Fit a Poisson regression model to these data, and compare the estimated coefficients with the true coefficients. How well does the estimated model predict future observations?

(b) Simulate 100 Poisson responses using the model $$log λ = 2 − bx$$ where $b$ is normally distributed with mean 4 and standard deviation 5. [Use the argument `slope.sd=5` in the `poissonsim()` function.] How do the results using the poisson and quasipoisson families differ?


